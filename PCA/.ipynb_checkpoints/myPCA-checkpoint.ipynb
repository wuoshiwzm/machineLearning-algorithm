{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 向量点乘 -> 投影\n",
    "\n",
    "$$ \\text{a}\\centerdot b=|\\text{a}||b|\\cos \\theta  $$\n",
    "\n",
    "|b|=1时，原式化为 $ a\\centerdot b=|a|\\cos \\theta  $\n",
    "\n",
    "推导：利用余弦定理 :${{c}^{2}}={{a}^{2}}+{{b}^{2}}-2|a||b|\\cos \\theta$\n",
    "\n",
    "\n",
    "\n",
    "## 基 -> 基变换 base\n",
    "\n",
    "基变换就是一种投影\n",
    "\n",
    "## 找这样的基->协方差矩阵\n",
    "\n",
    "方向：如何选择这个方向（或者说基）才能尽量保留最多的原始信息 ： 希望投影后的投影点尽可能分散\n",
    "\n",
    "方差： Var(a) = $\\frac{1}{m}\\sum\\limits_{i=1}^{m}{{{({{a}_{i}}-\\mu )}^{2}}}$\n",
    "\n",
    "寻找一个 【一维基】, 使得所有数据变换为这个基上的坐标表示后，方差值最大（第一个基）\n",
    "\n",
    "协方差（假设均值为0时）：Cov(a,b)= $\\frac{1}{m}\\sum\\limits_{i=1}^{m}{{{a}_{i}}{{b}_{i}}}$\n",
    " ，协方差（Covariance）在概率论和统计学中用于衡量两个变量的总体误差，cov(X,X) = var(X)，也就是说变量与自己的协方差就是方差\n",
    " \n",
    "目的是找到彼此协方差接近或为0的基,表示第二个基只能在与第一个基【正交】的方向上选择\n",
    "\n",
    "第一个基：方差最大的一个方向\n",
    "第二个基：正交于第一个基"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA(主成分分析)：\n",
    "将一组N维向量降为K维（K>0，K<N）,目标是选择【K个单位正交基】，使原始数据变换到这组基上后，各字段两两间协方差为0，方差尽可能大\n",
    "\n",
    "### 协方差矩阵：\n",
    "令：\n",
    "$$X=\\left( \\begin{matrix}\n",
    "   {{a}_{1}} & {{a}_{2}} & ... & {{a}_{m}}  \\\\\n",
    "   {{b}_{1}} & {{b}_{2}} & ... & {{b}_{m}}  \\\\\n",
    "\\end{matrix} \\right)$$\n",
    "\n",
    "有：\n",
    "$$协方差矩阵Cov = \\frac{1}{m}X{{X}^{T}}=\\left( \\begin{matrix}\n",
    "   \\frac{1}{m}\\sum\\limits_{i=1}^{m}{{{a}_{i}}^{2}} & \\frac{1}{m}\\sum\\limits_{i=1}^{m}{{{a}_{i}}{{b}_{i}}}  \\\\\n",
    "   \\frac{1}{m}\\sum\\limits_{i=1}^{m}{{{a}_{i}}{{b}_{i}}} & \\frac{1}{m}\\sum\\limits_{i=1}^{m}{{{b}_{i}}^{2}}  \\\\\n",
    "\\end{matrix} \\right)\n",
    "$$\n",
    "\n",
    "矩阵对角线上的两个元素分别是两个字段的方差，其他元素是a和b的协方差，且是【对称阵】\n",
    "\n",
    "对角化\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA流程：\n",
    "1：数据\n",
    "2：协方差矩阵\n",
    "3：eigen value 特征值 特征向量\n",
    "4：对角化\n",
    "5：降维\n",
    "\n",
    "比如100维降到10维，就最后取前10大的特征值，构成特征举证，数据为111x100， 111条数据，每条100维，特征矩阵为 100x10, 将乘后将数据降为111x10的维度！"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
