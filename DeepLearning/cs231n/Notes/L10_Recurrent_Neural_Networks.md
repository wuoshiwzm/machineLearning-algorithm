# L10: Recurrent Neural Networks


## 1. Vanilla RNN layer

RNN的关键就在于会把之前的信息保留下来，很适合处理序列。Rnn层如下：

![l10_rnn_layer.png](./Images/l10_rnn_layer.png)

![l10_rnn_layer2.png](./Images/l10_rnn_layer2.png)

一个RNN层和一个输出层的network

![l10_rnn_layer3.png](./Images/l10_rnn_layer3.png)


## 2. Image Captioning

![l10_image_caption.png](./Images/l10_image_caption.png)

## 3. LSTM

RNN训练的时候容易出现梯度爆炸和梯度消失的问题，LSTM效果更好

LSTM的记忆性能RNN更好, f是forget gates。

![l10_lstm.png](./Images/l10_lstm.png)


## 4. Summary

![l10_summary.png](./Images/l10_summary.png)

